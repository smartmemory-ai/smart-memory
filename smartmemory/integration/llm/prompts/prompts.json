{
  "extractor": {
    "ontology": {
      "system_template": "You are an expert knowledge graph extractor. Extract entities and relationships from text using this EXACT ontology schema.\n\nENTITY TYPES (choose from these ONLY):\n{{node_types_desc}}\n\nRELATIONSHIP TYPES (choose from these ONLY):\n{{relation_types_desc}}\n\nINSTRUCTIONS:\n1. Extract ONLY real entities (people, organizations, locations, concepts, etc.)\n2. Do NOT extract verbs, prepositions, or partial phrases as entities\n3. Classify each entity using the EXACT node type from the schema above\n4. For relationships, use ONLY the semantic types listed above - NO generic \"related\" relationships\n5. Only create relationships that make semantic sense between the entity types\n6. Return valid JSON with this exact structure:\n\n{\n  \"entities\": [\n    {\n      \"name\": \"entity name\",\n      \"type\": \"exact_node_type_from_schema\",\n      \"properties\": {\n        \"relevant_property\": \"value\"\n      }\n    }\n  ],\n  \"relationships\": [\n    {\n      \"source\": \"source entity name\",\n      \"target\": \"target entity name\", \n      \"type\": \"exact_relationship_type_from_schema\",\n      \"confidence\": 0.8\n    }\n  ]\n}\n\nBe precise and conservative - only extract clear, unambiguous entities and relationships.",
      "user_template": "Extract entities and relationships from this text:\n\n{{input_text}}"
    }
  },
  "plugins": {
    "extractors": {
      "llm": {
        "system_template": "You are an information-extraction engine.\n\nGOAL\nAlways extract subject–predicate–object triples when possible. Also enumerate salient entities.\n\nRULES\n- Extract only explicit facts from the provided text (no prior turns).\n- Resolve pronouns only when the referent is unambiguous in this text.\n- Predicates must be concise (≤3 words before normalisation).\n- Normalise predicates to FalkorDB-safe labels: lowercase, non-alphanumerics -> '_', collapse duplicates, trim, start with a letter; length ≤63.\n- Capture explicit negation via polarity='negative'.\n- Use entity types from: person, organization, location, concept, event, tool, skill.\n- Do not invent facts. Use only the defined tools; emit no prose.",
        "user_template": "TEXT:\n{{input_text}}\n\nTASK:\nUse add_entity for salient entities, and add_triple for each explicit fact found.",
        "json_fallback_template": "Extract entities and SPO triples from the text. Return a JSON object with keys: 'entities' (list of objects with name, entity_type, confidence, attrs), and 'triples' (list of objects with subject, predicate, object). Text: {{input_text}}"
      }
    }
  },
  "cleanup": {
    "normalization": {
      "system_template": "Clean and normalize the extracted entities and relationships:\n\nNORMALIZATION RULES:\n- Resolve entity mentions to canonical forms (e.g., \"Apple Inc.\" → \"Apple Inc.\")\n- Remove duplicates and low-confidence extractions (< 0.5 confidence)\n- Validate entity types against: person, organization, location, concept, event, tool, skill\n- Normalize predicates to FalkorDB-safe labels: lowercase, non-alphanumerics → '_'\n- Ensure predicate length ≤ 63 characters\n\nINPUT FORMAT:\nRaw extractions: {{raw_entities}}\n\nOUTPUT FORMAT:\nReturn cleaned JSON with:\n{\n  \"entities\": [{\"name\": \"canonical_name\", \"type\": \"validated_type\", \"confidence\": 0.8}],\n  \"relationships\": [{\"source\": \"entity1\", \"target\": \"entity2\", \"type\": \"normalized_predicate\", \"confidence\": 0.9}]\n}\n\nBe conservative - only keep high-confidence, well-formed extractions.",
      "user_template": "Clean and normalize these raw extractions:\n\n{{raw_entities}}"
    }
  },
  "enrichers": {
    "temporal": {
      "prompt_template": "Given the following text, extract for each entity the valid_start, valid_end, and transaction_time (if available) in ISO format. Return a JSON object mapping each entity to its temporal info. If not available, leave the field null.\n\nText: <TEXT>\n\nEntities: <ENTITIES>\n\nOutput example: {\"Alice\": {\"valid_start\": \"2020-01-01\", \"valid_end\": null, \"transaction_time\": \"2022-04-27T12:00:00\"}, ...}"
    }
  },
  "ontology": {
    "manager": {
      "analysis_template": "Analyze the following ontology for completeness, consistency, and quality:\n\nONTOLOGY OVERVIEW:\n- Name: <ONTOLOGY_NAME>\n- Domain: <ONTOLOGY_DOMAIN>\n- Entity Types: <ENTITY_TYPES_COUNT>\n- Relationship Types: <RELATIONSHIP_TYPES_COUNT>\n\nENTITY TYPES:\n<ENTITY_TYPES_JSON>\n\nRELATIONSHIP TYPES:\n<RELATIONSHIP_TYPES_JSON>\n\n<EXTRACTION_PATTERNS_BLOCK>\n\nPlease provide a comprehensive analysis including:\n1. Coverage Score (0.0-1.0): How well the ontology covers the domain\n2. Consistency Score (0.0-1.0): Internal consistency of definitions\n3. Completeness Score (0.0-1.0): Missing entity/relationship types\n4. Overall Quality Score (0.0-1.0): Overall assessment\n5. Gaps Identified: List of missing concepts or relationships\n6. Improvement Suggestions: Specific recommendations\n7. New Entity Types: Suggested new entity types with properties\n8. New Relationship Types: Suggested new relationship types\n9. Rule Suggestions: Validation or enrichment rules to add\n10. Confidence (0.0-1.0): Your confidence in this analysis\n\nRespond in JSON format with these exact keys.",
      "improvement_template": "Based on the following ontology analysis, create a detailed improvement plan:\n\nANALYSIS RESULTS:\n- Coverage Score: <COVERAGE_SCORE>\n- Consistency Score: <CONSISTENCY_SCORE>\n- Completeness Score: <COMPLETENESS_SCORE>\n- Overall Quality: <OVERALL_QUALITY>\n\nIDENTIFIED GAPS:\n<GAPS_JSON>\n\nIMPROVEMENT SUGGESTIONS:\n<IMPROVEMENTS_JSON>\n\nNEW ENTITY TYPES:\n<NEW_ENTITY_TYPES_JSON>\n\nNEW RELATIONSHIP TYPES:\n<NEW_RELATIONSHIP_TYPES_JSON>\n\nPlease create a prioritized evolution plan with:\n1. Priority Level: \"high\", \"medium\", or \"low\"\n2. Specific Changes: List of concrete changes to make\n3. Rationale: Why these changes are needed\n4. Estimated Impact: Expected improvement\n5. Risk Assessment: \"low\", \"medium\", or \"high\"\n6. Approval Required: true/false\n\nRespond in JSON format.",
      "domain_enrichment_template": "Enrich the following ontology with domain-specific knowledge for: <DOMAIN>\n\nCURRENT ONTOLOGY:\n- Name: <ONTOLOGY_NAME>\n- Domain: <ONTOLOGY_DOMAIN>\n- Entity Types: <ENTITY_TYPES_LIST>\n- Relationship Types: <RELATIONSHIP_TYPES_LIST>\n\nPlease suggest domain-specific enrichments including:\n1. Additional entity types relevant to <DOMAIN>\n2. Additional relationship types for <DOMAIN>\n3. Properties to add to existing entity types\n4. Validation rules specific to <DOMAIN>\n5. Hierarchical relationships between entity types\n\nFocus on practical, commonly used concepts in <DOMAIN>.\nRespond in JSON format with structured enrichments.",
      "validation_template": "Validate the following ontology for structural and semantic issues:\n\nONTOLOGY: <ONTOLOGY_NAME>\nENTITY TYPES: <ENTITY_TYPES_LIST>\nRELATIONSHIP TYPES: <RELATIONSHIP_TYPES_LIST>\n\nCheck for:\n1. Naming consistency\n2. Circular dependencies\n3. Missing required relationships\n4. Overly broad or narrow definitions\n5. Semantic conflicts\n6. Incomplete hierarchies\n\nRespond with validation results in JSON format."
    },
    "inference": {
      "concept_template": "Extract concepts and their synonyms from the following text. Return JSON with exact quotes and character spans.\n\nText: <TEXT>\n\nReturn JSON format:\n{\n  \"concepts\": [\n    {\n      \"label\": \"disease\",\n      \"synonyms\": [\"illness\", \"disorder\"],\n      \"confidence\": 0.9,\n      \"quote\": \"exact text span\",\n      \"span\": [120, 168]\n    }\n  ]\n}",
      "relation_template": "Extract semantic relations from the following text. Identify domain and range concepts. Return JSON with exact quotes.\n\nText: <TEXT>\n\nReturn JSON format:\n{\n  \"relations\": [\n    {\n      \"label\": \"treats\",\n      \"aliases\": [\"is used to treat\", \"helps\"],\n      \"domain\": \"drug\",\n      \"range\": \"disease\", \n      \"confidence\": 0.8,\n      \"quote\": \"exact text span\"\n    }\n  ]\n}"
    }
  }
}
